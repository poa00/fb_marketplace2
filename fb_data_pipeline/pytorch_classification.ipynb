{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from clean_data import CleanTabular, CleanImage\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pytorch import FbDataset, CNN, Resnet50, train, accuracy\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(os.path.dirname(os.getcwd()), 'image_data', 'fb_image')\n",
    "image_cleaner = CleanImage(image_path)\n",
    "cleaned_img_folder = image_cleaner.process_images(resized_pixel=(128, 128), mode = 'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = os.path.dirname(os.getcwd())\n",
    "cleaned_img_folder = os.path.join(parent_path, \"cleaned_image_data\")\n",
    "cleaned_image_paths = []\n",
    "for dirpaths, dirnames, filenames in os.walk(cleaned_img_folder):\n",
    "    for filename in filenames:\n",
    "        cleaned_image_paths.append(os.path.join(cleaned_img_folder, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_cleaner = CleanTabular(os.path.join(os.path.dirname(os.getcwd()), 'data/Images.csv'))\n",
    "tabular_cleaner.slice_df(['id', 'product_id'])\n",
    "image_df = tabular_cleaner.df\n",
    "image_df['image_data'] = np.NaN\n",
    "image_df['image_data']=image_df['image_data'].astype('object')\n",
    "\n",
    "convert_tensor = transforms.ToTensor()\n",
    "\n",
    "for i in range(len(image_df['id'])):\n",
    "    img = Image.open(os.path.join(cleaned_img_folder, image_df['id'][i] + '.jpg'))\n",
    "    tensor = convert_tensor(img)\n",
    "    numpydata = tensor.numpy()\n",
    "    image_df.at[i, 'image_data'] = numpydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_cleaner = CleanTabular(os.path.join(os.path.dirname(os.getcwd()), 'data/Products.csv'))\n",
    "tabular_cleaner.slice_df(['id', 'category'])\n",
    "tabular_cleaner.clean_to_general_category('category')\n",
    "cat_code_mapper = tabular_cleaner.clean_to_category_type('category', ohe=False)\n",
    "product_df = tabular_cleaner.df\n",
    "product_df = product_df.rename(columns={'id':'product_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = image_df.merge(product_df, how='left', on='product_id')\n",
    "merged_df = merged_df.drop(['product_id'], axis=1)\n",
    "merged_df = merged_df.drop(['id'], axis=1)\n",
    "# merged_df.to_csv('merged_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  1,  2,  9, 11,  4,  0,  7,  3, 10,  5,  8, 12], dtype=int8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_dataset = FbDataset(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, discard = torch.utils.data.random_split(fb_dataset, [1000, 11604])\n",
    "train_set, test_set = torch.utils.data.random_split(train_set, [800, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, shuffle = True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(3, 565504)\n",
    "train(model, train_loader, 0.001, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/serenawong/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/Users/serenawong/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "/Users/serenawong/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08875\n",
      "val ended\n",
      "0.2175\n",
      "val ended\n"
     ]
    }
   ],
   "source": [
    "model_resnet50 = Resnet50()\n",
    "accuracy(model_resnet50, train_set)\n",
    "print('val ended')\n",
    "train(model_resnet50, train_loader, 0.03, epochs = 10, model_name='resnet50_200dataaset')\n",
    "accuracy(model_resnet50, train_set)\n",
    "print('val ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/serenawong/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Resnet50()\n",
    "state_dict = torch.load(os.path.join('model_evaluation', 'resnet50_200dataaset','weights', \"2022-10-02 19:22:31.827969.pt\"))\n",
    "new_model.load_state_dict(state_dict)\n",
    "accuracy(new_model, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorboard-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5d3e1e0ed89e7e67e0fe11560c920f3252a17cdae2793b13e5f53142eea292a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
